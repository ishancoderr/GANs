{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled55.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXKBc6oTZMOeuBt63SFSjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishancoderr/GANs/blob/main/002_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwVCMwU4TlHG"
      },
      "outputs": [],
      "source": [
        "# supress warnings\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset \n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALT2ohimXjCE",
        "outputId": "6dd358c3-9d00-4090-835b-e519056ba811"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRDsEm_jYTN7",
        "outputId": "c5b92a47-e9c0-42f8-c3c1-ee7a67ea083f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17463646019789990335\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height =28,28\n",
        "img_channel = 1\n",
        "img_shape = (img_width, img_height, img_channel)\n",
        "num_classes = 10\n",
        "z_dim = 100"
      ],
      "metadata": {
        "id": "xoJojD4PYaSj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Generator**"
      ],
      "metadata": {
        "id": "N0za4K0XZvoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import UpSampling2D, Reshape, Activation, Conv2D, BatchNormalization, LeakyReLU, Input, Flatten, multiply\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.models import Sequential, Model"
      ],
      "metadata": {
        "id": "YXmnR_idbxPh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generater():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128*7*7, activation = 'relu', input_shape = (z_dim, )))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.02))\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(64, kernel_size = 3, strides = 1, padding = 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.02))\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(1, kernel_size = 3 , strides = 1, padding='same'))\n",
        "  model.add(Activation('tanh'))\n",
        "  z = Input(shape= (z_dim,))\n",
        "  label = Input(shape=(1,), dtype = 'int32')\n",
        "    \n",
        "  label_embedding = Embedding(num_classes, z_dim, input_length = 1)(label)\n",
        "  label_embedding = Flatten()(label_embedding)\n",
        "  joined = multiply([z, label_embedding])\n",
        "    \n",
        "  img = model(joined)\n",
        "  return Model([z, label], img) \n",
        "\n",
        "\n",
        "generator = build_generater()\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnOhTWQIb_DM",
        "outputId": "8973e6a4-5d89-453a-df29-4aa3470b0406"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 100)       1000        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 100)          0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 100)          0           ['input_1[0][0]',                \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 28, 28, 1)    856193      ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 857,193\n",
            "Trainable params: 856,809\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, Concatenate\n",
        "import numpy as np\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size = 3, strides = 2, input_shape = (28,28,2), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    \n",
        "    img = Input(shape= (img_shape))\n",
        "    label = Input(shape= (1,), dtype = 'int32')\n",
        "    \n",
        "    label_embedding = Embedding(input_dim = num_classes, output_dim = np.prod(img_shape), input_length = 1)(label)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    \n",
        "    concat = Concatenate(axis = -1)([img, label_embedding])\n",
        "    prediction = model(concat)\n",
        "    return Model([img, label], prediction)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XGYi4ggtLWb",
        "outputId": "fbe20ba2-3074-45ff-ac17-5154f9ebc7ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 784)       7840        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 784)          0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 28, 28, 1)    0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 2)    0           ['input_3[0][0]',                \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 1)            95905       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 103,745\n",
            "Trainable params: 103,297\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(0.0002, 0.5), metrics = ['accuracy'])\n",
        "\n",
        "z = Input(shape=(z_dim,))\n",
        "label = Input(shape= (1,))\n",
        "img = generator([z,label])\n",
        "\n",
        "discriminator.trainable = False\n",
        "prediction = discriminator([img, label])\n",
        "\n",
        "cgan = Model([z, label], prediction)\n",
        "cgan.compile(loss= 'binary_crossentropy', optimizer = Adam(0.0002, 0.5))"
      ],
      "metadata": {
        "id": "UjEPBwbQtVr7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size, save_interval):\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    \n",
        "    X_train = (X_train - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    \n",
        "    real = np.ones(shape=(batch_size, 1))\n",
        "    fake = np.zeros(shape=(batch_size, 1))\n",
        "    \n",
        "    for iteration in range(epochs):\n",
        "        \n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "        \n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        \n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "        \n",
        "        if iteration % save_interval == 0:\n",
        "            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "            save_image(iteration)"
      ],
      "metadata": {
        "id": "ItVOnDcttli7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def save_image(epoch):\n",
        "    r, c = 2,5\n",
        "    z = np.random.normal(0,1,(r*c, z_dim))\n",
        "    labels = np.arange(0,10).reshape(-1,1)\n",
        "    gen_image = generator.predict([z,labels])\n",
        "    gen_image = 0.5 * gen_image + 0.5\n",
        "    \n",
        "    fig, axes = plt.subplots(r,c, figsize = (10,10))\n",
        "    count = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axes[i,j].imshow(gen_image[count,:,:,0],cmap = 'gray')\n",
        "            axes[i,j].axis('off')\n",
        "            axes[i,j].set_title(\"Digit: %d\" % labels[count])\n",
        "            count+=1\n",
        "    plt.savefig('/content/sample_data/sample/cgan_%d.jpg' % epoch)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "dnCviq-ktp_K"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train network\n",
        "train(50000, 128, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxonX_y_tuL0",
        "outputId": "c7e2a49f-a1a1-44e0-b04a-196c8490e188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 0.0012481372395996004, accuracy: 100.00] [G loss: 0.00010639049287419766]\n"
          ]
        }
      ]
    }
  ]
}